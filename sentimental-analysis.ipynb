{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting depression in Tweets using Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing and importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.4-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting numpy>=1.6.1 (from wordcloud)\n",
      "  Using cached numpy-2.2.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pillow (from wordcloud)\n",
      "  Using cached pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting matplotlib (from wordcloud)\n",
      "  Using cached matplotlib-3.9.3-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->wordcloud)\n",
      "  Using cached contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->wordcloud)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->wordcloud)\n",
      "  Using cached fonttools-4.55.2-cp312-cp312-win_amd64.whl.metadata (168 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->wordcloud)\n",
      "  Using cached kiwisolver-1.4.7-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\poorn\\onedrive\\documents\\scribe\\env\\lib\\site-packages (from matplotlib->wordcloud) (24.2)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->wordcloud)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\poorn\\onedrive\\documents\\scribe\\env\\lib\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\poorn\\onedrive\\documents\\scribe\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
      "Downloading wordcloud-1.9.4-cp312-cp312-win_amd64.whl (301 kB)\n",
      "Using cached numpy-2.2.0-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached matplotlib-3.9.3-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "Using cached pillow-11.0.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.55.2-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.7-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib, wordcloud\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.2 kiwisolver-1.4.7 matplotlib-3.9.3 numpy-2.2.0 pillow-11.0.0 pyparsing-3.2.0 wordcloud-1.9.4\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\poorn\\onedrive\\documents\\scribe\\env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\poorn\\onedrive\\documents\\scribe\\env\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.2 nltk-3.9.1 regex-2024.11.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\poorn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log, sqrt\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\poorn\\onedrive\\documents\\scribe\\env\\lib\\site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\poorn\\onedrive\\documents\\scribe\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\poorn\\onedrive\\documents\\scribe\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>message to examine</th>\n",
       "      <th>label (depression result)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>just had a real good moment. i missssssssss hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217</td>\n",
       "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288</td>\n",
       "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>540</td>\n",
       "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>624</td>\n",
       "      <td>so sleepy. good times tonight though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>701</td>\n",
       "      <td>@SilkCharm re: #nbn as someone already said, d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>808</td>\n",
       "      <td>23 or 24ï¿½C possible today. Nice</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1193</td>\n",
       "      <td>nite twitterville  workout in the am  -ciao</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1324</td>\n",
       "      <td>@daNanner Night, darlin'!  Sweet dreams to you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1332</td>\n",
       "      <td>Good morning everybody!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1368</td>\n",
       "      <td>Finally! I just created my WordPress Blog. The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1578</td>\n",
       "      <td>kisha they cnt get over u til they get out frm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1595</td>\n",
       "      <td>@nicolerichie Yes i remember that band, It was...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1861</td>\n",
       "      <td>I really love reflections and shadows</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1889</td>\n",
       "      <td>@blueaero ooo it's fantasy?  i like fantasy no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1899</td>\n",
       "      <td>@rokchic28 no probs, I sell nothing other than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1919</td>\n",
       "      <td>@shipovalov &amp;quot;NOKLA connecting people&amp;quot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1992</td>\n",
       "      <td>Once again stayed up to late and have to start...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2097</td>\n",
       "      <td>@Kal_Penn I just read about your new job, CONG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index                                 message to examine  \\\n",
       "0     106  just had a real good moment. i missssssssss hi...   \n",
       "1     217         is reading manga  http://plurk.com/p/mzp1e   \n",
       "2     220  @comeagainjen http://twitpic.com/2y2lx - http:...   \n",
       "3     288  @lapcat Need to send 'em to my accountant tomo...   \n",
       "4     540      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
       "5     624              so sleepy. good times tonight though    \n",
       "6     701  @SilkCharm re: #nbn as someone already said, d...   \n",
       "7     808                 23 or 24ï¿½C possible today. Nice    \n",
       "8    1193        nite twitterville  workout in the am  -ciao   \n",
       "9    1324    @daNanner Night, darlin'!  Sweet dreams to you    \n",
       "10   1332                           Good morning everybody!    \n",
       "11   1368  Finally! I just created my WordPress Blog. The...   \n",
       "12   1578  kisha they cnt get over u til they get out frm...   \n",
       "13   1595  @nicolerichie Yes i remember that band, It was...   \n",
       "14   1861             I really love reflections and shadows    \n",
       "15   1889  @blueaero ooo it's fantasy?  i like fantasy no...   \n",
       "16   1899  @rokchic28 no probs, I sell nothing other than...   \n",
       "17   1919  @shipovalov &quot;NOKLA connecting people&quot...   \n",
       "18   1992  Once again stayed up to late and have to start...   \n",
       "19   2097  @Kal_Penn I just read about your new job, CONG...   \n",
       "\n",
       "    label (depression result)  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "5                           0  \n",
       "6                           0  \n",
       "7                           0  \n",
       "8                           0  \n",
       "9                           0  \n",
       "10                          0  \n",
       "11                          0  \n",
       "12                          0  \n",
       "13                          0  \n",
       "14                          0  \n",
       "15                          0  \n",
       "16                          0  \n",
       "17                          0  \n",
       "18                          0  \n",
       "19                          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('input/sentiment_tweets3.csv')\n",
    "tweets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtweets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\scribe\\env\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\scribe\\env\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\scribe\\env\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\scribe\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "tweets.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\Documents\\scribe\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtweets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\scribe\\env\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\scribe\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "tweets['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.450356Z",
     "iopub.status.idle": "2021-10-01T10:05:06.450856Z",
     "shell.execute_reply": "2021-10-01T10:05:06.450615Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.450587Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data in Training and Testing Sets\n",
    "\n",
    "As you can see, I almost used all the data for training (98%) and rest for testing. Please note that this is not a very good practice always. You should always maintain somewhere around a 70-30 train-test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.453521Z",
     "iopub.status.idle": "2021-10-01T10:05:06.454029Z",
     "shell.execute_reply": "2021-10-01T10:05:06.453777Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.453751Z"
    }
   },
   "outputs": [],
   "source": [
    "totalTweets = 8000 + 2314\n",
    "trainIndex, testIndex = list(), list()\n",
    "for i in range(tweets.shape[0]):\n",
    "    if np.random.uniform(0, 1) < 0.98:\n",
    "        trainIndex += [i]\n",
    "    else:\n",
    "        testIndex += [i]\n",
    "trainData = tweets.iloc[trainIndex]\n",
    "testData = tweets.iloc[testIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.455315Z",
     "iopub.status.idle": "2021-10-01T10:05:06.455795Z",
     "shell.execute_reply": "2021-10-01T10:05:06.455556Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.455530Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.456857Z",
     "iopub.status.idle": "2021-10-01T10:05:06.457349Z",
     "shell.execute_reply": "2021-10-01T10:05:06.457110Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.457085Z"
    }
   },
   "outputs": [],
   "source": [
    "trainData['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.458908Z",
     "iopub.status.idle": "2021-10-01T10:05:06.459530Z",
     "shell.execute_reply": "2021-10-01T10:05:06.459383Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.459365Z"
    }
   },
   "outputs": [],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.460367Z",
     "iopub.status.idle": "2021-10-01T10:05:06.461054Z",
     "shell.execute_reply": "2021-10-01T10:05:06.460877Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.460858Z"
    }
   },
   "outputs": [],
   "source": [
    "testData['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.461760Z",
     "iopub.status.idle": "2021-10-01T10:05:06.462397Z",
     "shell.execute_reply": "2021-10-01T10:05:06.462240Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.462222Z"
    }
   },
   "outputs": [],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.463160Z",
     "iopub.status.idle": "2021-10-01T10:05:06.463755Z",
     "shell.execute_reply": "2021-10-01T10:05:06.463612Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.463595Z"
    }
   },
   "outputs": [],
   "source": [
    "depressive_words = ' '.join(list(tweets[tweets['label'] == 1]['message']))\n",
    "depressive_wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(depressive_words)\n",
    "plt.figure(figsize = (10, 8), facecolor = 'k')\n",
    "plt.imshow(depressive_wc)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.464598Z",
     "iopub.status.idle": "2021-10-01T10:05:06.465189Z",
     "shell.execute_reply": "2021-10-01T10:05:06.465025Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.465006Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_words = ' '.join(list(tweets[tweets['label'] == 0]['message']))\n",
    "positive_wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(positive_words)\n",
    "plt.figure(figsize = (10, 8), facecolor = 'k')\n",
    "plt.imshow(positive_wc)\n",
    "plt.axis('off'), \n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing the data for the training: Tokenization, stemming, and removal of stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.466409Z",
     "iopub.status.idle": "2021-10-01T10:05:06.466711Z",
     "shell.execute_reply": "2021-10-01T10:05:06.466567Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.466552Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_message(message, lower_case = True, stem = True, stop_words = True, gram = 2):\n",
    "    if lower_case:\n",
    "        message = message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words = [w for w in words if len(w) > 2]\n",
    "    if gram > 1:\n",
    "        w = []\n",
    "        for i in range(len(words) - gram + 1):\n",
    "            w += [' '.join(words[i:i + gram])]\n",
    "        return w\n",
    "    if stop_words:\n",
    "        sw = stopwords.words('english')\n",
    "        words = [word for word in words if word not in sw]\n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]   \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.467989Z",
     "iopub.status.idle": "2021-10-01T10:05:06.468301Z",
     "shell.execute_reply": "2021-10-01T10:05:06.468143Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.468129Z"
    }
   },
   "outputs": [],
   "source": [
    "class TweetClassifier(object):\n",
    "    def __init__(self, trainData, method = 'tf-idf'):\n",
    "        self.tweets, self.labels = trainData['message'], trainData['label']\n",
    "        self.method = method\n",
    "\n",
    "    def train(self):\n",
    "        self.calc_TF_and_IDF()\n",
    "        if self.method == 'tf-idf':\n",
    "            self.calc_TF_IDF()\n",
    "        else:\n",
    "            self.calc_prob()\n",
    "\n",
    "    def calc_prob(self):\n",
    "        self.prob_depressive = dict()\n",
    "        self.prob_positive = dict()\n",
    "        for word in self.tf_depressive:\n",
    "            self.prob_depressive[word] = (self.tf_depressive[word] + 1) / (self.depressive_words + \\\n",
    "                                                                len(list(self.tf_depressive.keys())))\n",
    "        for word in self.tf_positive:\n",
    "            self.prob_positive[word] = (self.tf_positive[word] + 1) / (self.positive_words + \\\n",
    "                                                                len(list(self.tf_positive.keys())))\n",
    "        self.prob_depressive_tweet, self.prob_positive_tweet = self.depressive_tweets / self.total_tweets, self.positive_tweets / self.total_tweets \n",
    "\n",
    "\n",
    "    def calc_TF_and_IDF(self):\n",
    "        noOfMessages = self.tweets.shape[0]\n",
    "        self.depressive_tweets, self.positive_tweets = self.labels.value_counts()[1], self.labels.value_counts()[0]\n",
    "        self.total_tweets = self.depressive_tweets + self.positive_tweets\n",
    "        self.depressive_words = 0\n",
    "        self.positive_words = 0\n",
    "        self.tf_depressive = dict()\n",
    "        self.tf_positive = dict()\n",
    "        self.idf_depressive = dict()\n",
    "        self.idf_positive = dict()\n",
    "        for i in range(noOfMessages):\n",
    "            message_processed = process_message(self.tweets.iloc[i])\n",
    "            count = list() #To keep track of whether the word has ocured in the message or not.\n",
    "                           #For IDF\n",
    "            for word in message_processed:\n",
    "                if self.labels.iloc[i]:\n",
    "                    self.tf_depressive[word] = self.tf_depressive.get(word, 0) + 1\n",
    "                    self.depressive_words += 1\n",
    "                else:\n",
    "                    self.tf_positive[word] = self.tf_positive.get(word, 0) + 1\n",
    "                    self.positive_words += 1\n",
    "                if word not in count:\n",
    "                    count += [word]\n",
    "            for word in count:\n",
    "                if self.labels.iloc[i]:\n",
    "                    self.idf_depressive[word] = self.idf_depressive.get(word, 0) + 1\n",
    "                else:\n",
    "                    self.idf_positive[word] = self.idf_positive.get(word, 0) + 1\n",
    "\n",
    "    def calc_TF_IDF(self):\n",
    "        self.prob_depressive = dict()\n",
    "        self.prob_positive = dict()\n",
    "        self.sum_tf_idf_depressive = 0\n",
    "        self.sum_tf_idf_positive = 0\n",
    "        for word in self.tf_depressive:\n",
    "            self.prob_depressive[word] = (self.tf_depressive[word]) * log((self.depressive_tweets + self.positive_tweets) \\\n",
    "                                                          / (self.idf_depressive[word] + self.idf_positive.get(word, 0)))\n",
    "            self.sum_tf_idf_depressive += self.prob_depressive[word]\n",
    "        for word in self.tf_depressive:\n",
    "            self.prob_depressive[word] = (self.prob_depressive[word] + 1) / (self.sum_tf_idf_depressive + len(list(self.prob_depressive.keys())))\n",
    "            \n",
    "        for word in self.tf_positive:\n",
    "            self.prob_positive[word] = (self.tf_positive[word]) * log((self.depressive_tweets + self.positive_tweets) \\\n",
    "                                                          / (self.idf_depressive.get(word, 0) + self.idf_positive[word]))\n",
    "            self.sum_tf_idf_positive += self.prob_positive[word]\n",
    "        for word in self.tf_positive:\n",
    "            self.prob_positive[word] = (self.prob_positive[word] + 1) / (self.sum_tf_idf_positive + len(list(self.prob_positive.keys())))\n",
    "            \n",
    "    \n",
    "        self.prob_depressive_tweet, self.prob_positive_tweet = self.depressive_tweets / self.total_tweets, self.positive_tweets / self.total_tweets \n",
    "                    \n",
    "    def classify(self, processed_message):\n",
    "        pDepressive, pPositive = 0, 0\n",
    "        for word in processed_message:                \n",
    "            if word in self.prob_depressive:\n",
    "                pDepressive += log(self.prob_depressive[word])\n",
    "            else:\n",
    "                if self.method == 'tf-idf':\n",
    "                    pDepressive -= log(self.sum_tf_idf_depressive + len(list(self.prob_depressive.keys())))\n",
    "                else:\n",
    "                    pDepressive -= log(self.depressive_words + len(list(self.prob_depressive.keys())))\n",
    "            if word in self.prob_positive:\n",
    "                pPositive += log(self.prob_positive[word])\n",
    "            else:\n",
    "                if self.method == 'tf-idf':\n",
    "                    pPositive -= log(self.sum_tf_idf_positive + len(list(self.prob_positive.keys()))) \n",
    "                else:\n",
    "                    pPositive -= log(self.positive_words + len(list(self.prob_positive.keys())))\n",
    "            pDepressive += log(self.prob_depressive_tweet)\n",
    "            pPositive += log(self.prob_positive_tweet)\n",
    "        return pDepressive >= pPositive\n",
    "    \n",
    "    def predict(self, testData):\n",
    "        result = dict()\n",
    "        for (i, message) in enumerate(testData):\n",
    "            processed_message = process_message(message)\n",
    "            result[i] = int(self.classify(processed_message))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.469365Z",
     "iopub.status.idle": "2021-10-01T10:05:06.469658Z",
     "shell.execute_reply": "2021-10-01T10:05:06.469521Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.469507Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(labels, predictions):\n",
    "    true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0\n",
    "    for i in range(len(labels)):\n",
    "        true_pos += int(labels.iloc[i] == 1 and predictions[i] == 1)\n",
    "        true_neg += int(labels.iloc[i] == 0 and predictions[i] == 0)\n",
    "        false_pos += int(labels.iloc[i] == 0 and predictions[i] == 1)\n",
    "        false_neg += int(labels.iloc[i] == 1 and predictions[i] == 0)\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    Fscore = 2 * precision * recall / (precision + recall)\n",
    "    accuracy = (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)\n",
    "\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F-score: \", Fscore)\n",
    "    print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.470781Z",
     "iopub.status.idle": "2021-10-01T10:05:06.472063Z",
     "shell.execute_reply": "2021-10-01T10:05:06.471803Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.471776Z"
    }
   },
   "outputs": [],
   "source": [
    "sc_tf_idf = TweetClassifier(trainData, 'tf-idf')\n",
    "sc_tf_idf.train()\n",
    "preds_tf_idf = sc_tf_idf.predict(testData['message'])\n",
    "metrics(testData['label'], preds_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.473345Z",
     "iopub.status.idle": "2021-10-01T10:05:06.474455Z",
     "shell.execute_reply": "2021-10-01T10:05:06.474168Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.474141Z"
    }
   },
   "outputs": [],
   "source": [
    "sc_bow = TweetClassifier(trainData, 'bow')\n",
    "sc_bow.train()\n",
    "preds_bow = sc_bow.predict(testData['message'])\n",
    "metrics(testData['label'], preds_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions with TF-IDF\n",
    "# Depressive Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.475740Z",
     "iopub.status.idle": "2021-10-01T10:05:06.476569Z",
     "shell.execute_reply": "2021-10-01T10:05:06.476307Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.476278Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Lately I have been feeling unsure of myself as a person & an artist')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.478023Z",
     "iopub.status.idle": "2021-10-01T10:05:06.479049Z",
     "shell.execute_reply": "2021-10-01T10:05:06.478784Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.478756Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Extreme sadness, lack of energy, hopelessness')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.480313Z",
     "iopub.status.idle": "2021-10-01T10:05:06.481347Z",
     "shell.execute_reply": "2021-10-01T10:05:06.481068Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.481039Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Hi hello depression and anxiety are the worst')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.482544Z",
     "iopub.status.idle": "2021-10-01T10:05:06.483015Z",
     "shell.execute_reply": "2021-10-01T10:05:06.482789Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.482765Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('I am officially done with @kanyewest')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.484708Z",
     "iopub.status.idle": "2021-10-01T10:05:06.485187Z",
     "shell.execute_reply": "2021-10-01T10:05:06.484958Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.484935Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Feeling down...')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.486326Z",
     "iopub.status.idle": "2021-10-01T10:05:06.486629Z",
     "shell.execute_reply": "2021-10-01T10:05:06.486489Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.486473Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('My depression will not let me work out')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.487376Z",
     "iopub.status.idle": "2021-10-01T10:05:06.487670Z",
     "shell.execute_reply": "2021-10-01T10:05:06.487533Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.487518Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Loving how me and my lovely partner is talking about what we want.')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.488716Z",
     "iopub.status.idle": "2021-10-01T10:05:06.489026Z",
     "shell.execute_reply": "2021-10-01T10:05:06.488881Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.488866Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Very rewarding when a patient hugs you and tells you they feel great after changing the diet and daily habits')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.489752Z",
     "iopub.status.idle": "2021-10-01T10:05:06.490044Z",
     "shell.execute_reply": "2021-10-01T10:05:06.489904Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.489889Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Happy Thursday everyone. Thought today was Wednesday so super happy tomorrow is Friday yayyyyy')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.490926Z",
     "iopub.status.idle": "2021-10-01T10:05:06.491257Z",
     "shell.execute_reply": "2021-10-01T10:05:06.491097Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.491082Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('It’s the little things that make me smile. Got our new car today and this arrived with it')\n",
    "sc_tf_idf.classify(pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions with Bag-of-Words (BOW)\n",
    "# Depressive tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.492015Z",
     "iopub.status.idle": "2021-10-01T10:05:06.492358Z",
     "shell.execute_reply": "2021-10-01T10:05:06.492179Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.492165Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Hi hello depression and anxiety are the worst')\n",
    "sc_bow.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.493733Z",
     "iopub.status.idle": "2021-10-01T10:05:06.494028Z",
     "shell.execute_reply": "2021-10-01T10:05:06.493888Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.493874Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('My depression will not let me work out')\n",
    "sc_bow.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.494760Z",
     "iopub.status.idle": "2021-10-01T10:05:06.495051Z",
     "shell.execute_reply": "2021-10-01T10:05:06.494909Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.494894Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Feeling down...')\n",
    "sc_bow.classify(pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.495846Z",
     "iopub.status.idle": "2021-10-01T10:05:06.496143Z",
     "shell.execute_reply": "2021-10-01T10:05:06.496004Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.495989Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Loving how me and my lovely partner is talking about what we want.')\n",
    "sc_bow.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.497070Z",
     "iopub.status.idle": "2021-10-01T10:05:06.497411Z",
     "shell.execute_reply": "2021-10-01T10:05:06.497258Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.497237Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Very rewarding when a patient hugs you and tells you they feel great after changing the diet and daily habits')\n",
    "sc_bow.classify(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-01T10:05:06.498391Z",
     "iopub.status.idle": "2021-10-01T10:05:06.498719Z",
     "shell.execute_reply": "2021-10-01T10:05:06.498568Z",
     "shell.execute_reply.started": "2021-10-01T10:05:06.498552Z"
    }
   },
   "outputs": [],
   "source": [
    "pm = process_message('Happy Thursday everyone. Thought today was Wednesday so super happy tomorrow is Friday yayyyyy')\n",
    "sc_bow.classify(pm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
